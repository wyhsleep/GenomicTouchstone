# Use open-source version of Mamba
_name_: baseline_lstm
config:
  _target_: src.models.othermodels.configuration_custom.LSTM_Config
  number_of_classes: ${dataset.d_output}
  vocab_size: 12
  embedding_dim: 100  # See: https://github.com/ML-Bioinfo-CEITEC/genomic_benchmarks/tree/main/experiments/torch_cnn_experiments
  input_len: ${dataset.__l_max}
  d_model: 512
  hidden_size: 512
  bidirectional: True
  num_layers: 2
